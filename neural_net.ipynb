{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1286,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "import json\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy\n",
    "\n",
    "\n",
    "\n",
    "random.seed(0)\n",
    "np.random.seed(0)\n",
    "torch.manual_seed(0)\n",
    "torch.cuda.manual_seed(0)\n",
    "torch.backends.cudnn.deterministic = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1287,
   "outputs": [],
   "source": [
    "with open('level_data.txt', 'r') as filehandle:\n",
    "    level_data = json.load(filehandle)\n",
    "with open('weather_data.txt', 'r') as filehandle:\n",
    "    weather_data = json.load(filehandle)\n",
    "\n",
    "dataset_x = []\n",
    "dataset_y = []\n",
    "for year in range(0, 19):\n",
    "    for month in [3, 4]:\n",
    "        lst = []\n",
    "        if month > 0:\n",
    "            for w in weather_data[year][month-1][len(weather_data[year][month-1])-90+len(weather_data[year][month]):] + weather_data[year][month]:\n",
    "                w['tempreture'] += 50\n",
    "                lst.append(list(w.values()))\n",
    "        else:\n",
    "            if year > 0:\n",
    "                for w in weather_data[year-1][11][len(weather_data[year-1][11]) - 90+len(weather_data[year][month]):] + weather_data[year][month]:\n",
    "                    w['tempreture'] += 50\n",
    "                    lst.append(list(w.values()))\n",
    "        if lst:\n",
    "            if len(lst) == 90:\n",
    "                dataset_x.append(lst)\n",
    "                dataset_y.append(level_data[year][month])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1288,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38\n"
     ]
    }
   ],
   "source": [
    "dataset_x = torch.Tensor(dataset_x)\n",
    "dataset_y = torch.Tensor(dataset_y)\n",
    "print(len(dataset_x))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1289,
   "outputs": [],
   "source": [
    "X_train = dataset_x[:35]\n",
    "y_train = dataset_y[:35]\n",
    "X_test = dataset_x[35:]\n",
    "y_test = dataset_y[35:]\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1290,
   "outputs": [
    {
     "data": {
      "text/plain": "(torch.float32, torch.float32)"
     },
     "execution_count": 1290,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "X_train.dtype, y_train.dtype\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1291,
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "X_train = X_train.float()\n",
    "y_train = y_train.float()\n",
    "X_test = X_test.float()\n",
    "y_test = y_test.float()\n",
    "f1 = torch.nn.ReLU()\n",
    "f2 = torch.nn.ReLU()\n",
    "y_test = f1(y_test)\n",
    "y_train = f2(y_train)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1292,
   "outputs": [
    {
     "data": {
      "text/plain": "(torch.Size([35, 90, 6]), torch.Size([3, 90, 6]))"
     },
     "execution_count": 1292,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "X_train.shape, X_test.shape\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1293,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[ 46., 773.,   4.,  ...,   0.,   2.,   5.],\n        [100., 754.,   1.,  ...,   0.,   5.,   4.],\n        [ 40., 759.,   1.,  ...,   0.,   6.,   4.],\n        ...,\n        [ 55., 738.,   4.,  ...,   0.,   6.,   4.],\n        [114., 756.,   3.,  ...,   0.,   8.,   3.],\n        [ 50., 770.,   1.,  ...,   0.,   7.,   1.]])"
     },
     "execution_count": 1293,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "X_train = X_train.reshape([-1,90 * 6])\n",
    "X_test = X_test.reshape([-1, 90 * 6])\n",
    "X_train.data\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1294,
   "outputs": [],
   "source": [
    "class RiverNet(torch.nn.Module):\n",
    "    def __init__(self, n_hidden_neurons):\n",
    "        super(RiverNet, self).__init__()\n",
    "        self.fc1 = torch.nn.Linear(90 * 6, n_hidden_neurons)\n",
    "        self.ac1 = torch.nn.ReLU()\n",
    "        self.fc2 = torch.nn.Linear(n_hidden_neurons, 512)\n",
    "        self.ac2 = torch.nn.ReLU()\n",
    "        self.fc3 = torch.nn.Linear(512, 256)\n",
    "        self.ac3 = torch.nn.ReLU()\n",
    "        self.fc4 = torch.nn.Linear(256, 128)\n",
    "        self.ac4 = torch.nn.ReLU()\n",
    "        self.fc5 = torch.nn.Linear(128, 64)\n",
    "        self.ac5 = torch.nn.ReLU()\n",
    "        self.fc6 = torch.nn.Linear(64, 32)\n",
    "        self.ac6 = torch.nn.ReLU()\n",
    "        self.fc7 = torch.nn.Linear(32, 1)\n",
    "        self.ac7 = torch.nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.ac1(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.ac2(x)\n",
    "        x = self.fc3(x)\n",
    "        x = self.ac3(x)\n",
    "        x = self.fc4(x)\n",
    "        x = self.ac4(x)\n",
    "        x = self.fc5(x)\n",
    "        x = self.ac5(x)\n",
    "        x = self.fc6(x)\n",
    "        x = self.ac6(x)\n",
    "        x = self.fc7(x)\n",
    "        x = self.ac7(x)\n",
    "        return x\n",
    "\n",
    "river_net = RiverNet(1000)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1295,
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "river_net = river_net.to(device)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1296,
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "loss = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(river_net.parameters(), lr=1.0e-3)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1297,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\ilya\\pycharmprojects\\river\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:529: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([1, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(89951.8203) 0\n",
      "tensor(62781.5156) 1\n",
      "tensor(36707.0195) 2\n",
      "tensor(39012.5430) 3\n",
      "tensor(47239.3633) 4\n",
      "tensor(115562.0938) 5\n",
      "tensor(36797.8164) 6\n",
      "tensor(36125.7539) 7\n",
      "tensor(50173.8164) 8\n",
      "tensor(40017.1250) 9\n",
      "tensor(47421.4531) 10\n",
      "tensor(55844.4180) 11\n",
      "tensor(84815.2422) 12\n",
      "tensor(50363.9062) 13\n",
      "tensor(41502.6992) 14\n",
      "tensor(35197.6133) 15\n",
      "tensor(34655.4492) 16\n",
      "tensor(36105.3750) 17\n",
      "tensor(37022.4531) 18\n",
      "tensor(42592.6328) 19\n",
      "tensor(35061.1523) 20\n",
      "tensor(34832.4727) 21\n",
      "tensor(34635.2656) 22\n",
      "tensor(33834.6914) 23\n",
      "tensor(34121.8633) 24\n",
      "tensor(70120.6094) 25\n",
      "tensor(37644.1445) 26\n",
      "tensor(33427.1562) 27\n",
      "tensor(44692.5195) 28\n",
      "tensor(37066.0156) 29\n",
      "tensor(38989.3242) 30\n",
      "tensor(33150.5352) 31\n",
      "tensor(36170.1094) 32\n",
      "tensor(38233.9336) 33\n",
      "tensor(34547.2148) 34\n",
      "tensor(39476.7812) 35\n",
      "tensor(32648.3281) 36\n",
      "tensor(34575.2930) 37\n",
      "tensor(44110.5312) 38\n",
      "tensor(42785.4727) 39\n",
      "tensor(37405.5938) 40\n",
      "tensor(53337.1992) 41\n",
      "tensor(31527.0527) 42\n",
      "tensor(34285.2461) 43\n",
      "tensor(35176.0156) 44\n",
      "tensor(31046.0527) 45\n",
      "tensor(39856.1211) 46\n",
      "tensor(31023.9707) 47\n",
      "tensor(44512.0898) 48\n",
      "tensor(34722.0117) 49\n",
      "tensor(41203.2969) 50\n",
      "tensor(38586.8320) 51\n",
      "tensor(47752.6367) 52\n",
      "tensor(53259.3086) 53\n",
      "tensor(32135.1035) 54\n",
      "tensor(36688.2383) 55\n",
      "tensor(38845.9570) 56\n",
      "tensor(35153.2852) 57\n",
      "tensor(30525.7676) 58\n",
      "tensor(30052.8438) 59\n",
      "tensor(34704.0664) 60\n",
      "tensor(36833.7695) 61\n",
      "tensor(29606.0781) 62\n",
      "tensor(33047.0273) 63\n",
      "tensor(31133.9629) 64\n",
      "tensor(47084.5820) 65\n",
      "tensor(30626.7129) 66\n",
      "tensor(32520.8301) 67\n",
      "tensor(30386.5312) 68\n",
      "tensor(38266.3086) 69\n",
      "tensor(44675.5000) 70\n",
      "tensor(35291.3398) 71\n",
      "tensor(28987.9590) 72\n",
      "tensor(30075.9082) 73\n",
      "tensor(30574.2969) 74\n",
      "tensor(33066.2773) 75\n",
      "tensor(35870.3398) 76\n",
      "tensor(33158.7305) 77\n",
      "tensor(29321.8691) 78\n",
      "tensor(33109.7969) 79\n",
      "tensor(35062.9023) 80\n",
      "tensor(34360.9844) 81\n",
      "tensor(46680.5938) 82\n",
      "tensor(50164.3945) 83\n",
      "tensor(34134.7344) 84\n",
      "tensor(39694.4727) 85\n",
      "tensor(40527.1523) 86\n",
      "tensor(29009.2793) 87\n",
      "tensor(50269.3867) 88\n",
      "tensor(42843.1602) 89\n",
      "tensor(28263.1191) 90\n",
      "tensor(34612.8789) 91\n",
      "tensor(45353.7852) 92\n",
      "tensor(27987.3848) 93\n",
      "tensor(35466.0156) 94\n",
      "tensor(28458.4824) 95\n",
      "tensor(41321.5234) 96\n",
      "tensor(30481.5371) 97\n",
      "tensor(35289.5938) 98\n",
      "tensor(34156.8164) 99\n",
      "tensor(33322.2305) 100\n",
      "tensor(33350.3945) 101\n",
      "tensor(32749.0684) 102\n",
      "tensor(27343.5723) 103\n",
      "tensor(32319.9434) 104\n",
      "tensor(26791.0762) 105\n",
      "tensor(34396.8789) 106\n",
      "tensor(31817.4395) 107\n",
      "tensor(31779.4824) 108\n",
      "tensor(26364.5781) 109\n",
      "tensor(33580.1367) 110\n",
      "tensor(39228.8320) 111\n",
      "tensor(31628.3672) 112\n",
      "tensor(27180.4316) 113\n",
      "tensor(27292.9160) 114\n",
      "tensor(25944.1660) 115\n",
      "tensor(40204.7227) 116\n",
      "tensor(30543.1543) 117\n",
      "tensor(27573.7441) 118\n",
      "tensor(29942.3047) 119\n",
      "tensor(32776.9414) 120\n",
      "tensor(26955.5410) 121\n",
      "tensor(49027.4570) 122\n",
      "tensor(36522.6133) 123\n",
      "tensor(28754.7578) 124\n",
      "tensor(30992.6973) 125\n",
      "tensor(28018.5410) 126\n",
      "tensor(26003.0098) 127\n",
      "tensor(29493.3926) 128\n",
      "tensor(40427.9961) 129\n",
      "tensor(32651.7090) 130\n",
      "tensor(25842.4062) 131\n",
      "tensor(38997.0859) 132\n",
      "tensor(41495.4375) 133\n",
      "tensor(27435.0371) 134\n",
      "tensor(25317.6035) 135\n",
      "tensor(28850.4160) 136\n",
      "tensor(38771.3867) 137\n",
      "tensor(34926.9492) 138\n",
      "tensor(24321.2891) 139\n",
      "tensor(31845.6777) 140\n",
      "tensor(42819.7617) 141\n",
      "tensor(43446.3555) 142\n",
      "tensor(30111.8203) 143\n",
      "tensor(24818.5918) 144\n",
      "tensor(26082.4062) 145\n",
      "tensor(31222.8184) 146\n",
      "tensor(32277.1309) 147\n",
      "tensor(27841.6250) 148\n",
      "tensor(32478.0156) 149\n",
      "tensor(25529.6875) 150\n",
      "tensor(40315.4414) 151\n",
      "tensor(27779.7598) 152\n",
      "tensor(25315.8516) 153\n",
      "tensor(30878.3418) 154\n",
      "tensor(25619.8066) 155\n",
      "tensor(43125.3086) 156\n",
      "tensor(25496.5879) 157\n",
      "tensor(24789.5410) 158\n",
      "tensor(26061.0723) 159\n",
      "tensor(25247.2812) 160\n",
      "tensor(27469.8066) 161\n",
      "tensor(29585.9844) 162\n",
      "tensor(25318.3223) 163\n",
      "tensor(35259.3086) 164\n",
      "tensor(30071.9062) 165\n",
      "tensor(25388.0723) 166\n",
      "tensor(24349.1621) 167\n",
      "tensor(24103.3984) 168\n",
      "tensor(23978.2324) 169\n",
      "tensor(23492.1934) 170\n",
      "tensor(30802.9863) 171\n",
      "tensor(24572.3301) 172\n",
      "tensor(24334.8262) 173\n",
      "tensor(34534.2734) 174\n",
      "tensor(33939.5312) 175\n",
      "tensor(25675.5000) 176\n",
      "tensor(23563.2324) 177\n",
      "tensor(23983.2910) 178\n",
      "tensor(36576.8867) 179\n",
      "tensor(27073.4941) 180\n",
      "tensor(24977.1035) 181\n",
      "tensor(28485.7910) 182\n",
      "tensor(24012.9512) 183\n",
      "tensor(23629.4629) 184\n",
      "tensor(23666.2598) 185\n",
      "tensor(29686.9453) 186\n",
      "tensor(24007.5410) 187\n",
      "tensor(33082.5156) 188\n",
      "tensor(34251.0352) 189\n",
      "tensor(23429.2656) 190\n",
      "tensor(36349.6133) 191\n",
      "tensor(115877.6875) 192\n",
      "tensor(33192.5039) 193\n",
      "tensor(29993.1875) 194\n",
      "tensor(29249.3750) 195\n",
      "tensor(29601.5391) 196\n",
      "tensor(33871.2227) 197\n",
      "tensor(26424.1816) 198\n",
      "tensor(26107.3965) 199\n",
      "tensor(23977.6855) 200\n",
      "tensor(25008.1426) 201\n",
      "tensor(84100.2266) 202\n",
      "tensor(31947.1719) 203\n",
      "tensor(27345.4707) 204\n",
      "tensor(29093.7031) 205\n",
      "tensor(31451.5156) 206\n",
      "tensor(27971.9941) 207\n",
      "tensor(39914.4570) 208\n",
      "tensor(26299.4062) 209\n",
      "tensor(28775.6387) 210\n",
      "tensor(54744.2070) 211\n",
      "tensor(27467.5605) 212\n",
      "tensor(26597.3652) 213\n",
      "tensor(32393.6016) 214\n",
      "tensor(30747.3691) 215\n",
      "tensor(24208.8281) 216\n",
      "tensor(26485.4434) 217\n",
      "tensor(25278.4922) 218\n",
      "tensor(26836.2578) 219\n",
      "tensor(22905.1699) 220\n",
      "tensor(33365.3633) 221\n",
      "tensor(25215.2715) 222\n",
      "tensor(21759.0312) 223\n",
      "tensor(27482.0449) 224\n",
      "tensor(21209.4512) 225\n",
      "tensor(30308.1094) 226\n",
      "tensor(23886.6875) 227\n",
      "tensor(37145.3008) 228\n",
      "tensor(48490.3242) 229\n",
      "tensor(24548.8145) 230\n",
      "tensor(26046.4297) 231\n",
      "tensor(25509.3340) 232\n",
      "tensor(47990.5898) 233\n",
      "tensor(32204.4609) 234\n",
      "tensor(24206.7422) 235\n",
      "tensor(46590.1875) 236\n",
      "tensor(39019.7930) 237\n",
      "tensor(23352.1250) 238\n",
      "tensor(28788.1719) 239\n",
      "tensor(62528.8477) 240\n",
      "tensor(35521.3125) 241\n",
      "tensor(34317.9180) 242\n",
      "tensor(23137.3438) 243\n",
      "tensor(34047.3125) 244\n",
      "tensor(22964.3613) 245\n",
      "tensor(43294.5625) 246\n",
      "tensor(27038.7168) 247\n",
      "tensor(31508.6113) 248\n",
      "tensor(41634.0391) 249\n",
      "tensor(23354.5859) 250\n",
      "tensor(46732.4023) 251\n",
      "tensor(22999.4434) 252\n",
      "tensor(23161.0098) 253\n",
      "tensor(49630.3164) 254\n",
      "tensor(23879.9434) 255\n",
      "tensor(24064.1895) 256\n",
      "tensor(25007.9238) 257\n",
      "tensor(29292.3770) 258\n",
      "tensor(23693.8965) 259\n",
      "tensor(29824.6172) 260\n",
      "tensor(46367.7461) 261\n",
      "tensor(38401.9805) 262\n",
      "tensor(53773.0195) 263\n",
      "tensor(31749.0879) 264\n",
      "tensor(30280.3457) 265\n",
      "tensor(37111.2930) 266\n",
      "tensor(52104.1875) 267\n",
      "tensor(29567.5957) 268\n",
      "tensor(29459.1641) 269\n",
      "tensor(44352.6289) 270\n",
      "tensor(54577.5586) 271\n",
      "tensor(39380.0352) 272\n",
      "tensor(34047.2461) 273\n",
      "tensor(47021.7070) 274\n",
      "tensor(35622.2266) 275\n",
      "tensor(38862.3281) 276\n",
      "tensor(56344.4492) 277\n",
      "tensor(36077.2227) 278\n",
      "tensor(43905.0312) 279\n",
      "tensor(42332.2930) 280\n",
      "tensor(39417.5117) 281\n",
      "tensor(56605.9062) 282\n",
      "tensor(38610.3398) 283\n",
      "tensor(42118.4922) 284\n",
      "tensor(46536.4414) 285\n",
      "tensor(72902.6953) 286\n",
      "tensor(34636.8516) 287\n",
      "tensor(34750.6094) 288\n",
      "tensor(39169.4492) 289\n",
      "tensor(36525.4883) 290\n",
      "tensor(38340.7617) 291\n",
      "tensor(34920.5039) 292\n",
      "tensor(45131.6445) 293\n",
      "tensor(41657.8867) 294\n",
      "tensor(37353.0898) 295\n",
      "tensor(44640.6680) 296\n",
      "tensor(60414.7930) 297\n",
      "tensor(34810.5508) 298\n",
      "tensor(93511.0703) 299\n",
      "tensor(38882.0312) 300\n",
      "tensor(34529.2070) 301\n",
      "tensor(47326.5156) 302\n",
      "tensor(46357.6367) 303\n",
      "tensor(57458.2383) 304\n",
      "tensor(61185.8945) 305\n",
      "tensor(42318.6641) 306\n",
      "tensor(72559.0938) 307\n",
      "tensor(61528.2305) 308\n",
      "tensor(44750.9883) 309\n",
      "tensor(39657.8750) 310\n",
      "tensor(46557.7930) 311\n",
      "tensor(40681.8086) 312\n",
      "tensor(45755.4414) 313\n",
      "tensor(44413.2617) 314\n",
      "tensor(50782.0742) 315\n",
      "tensor(43713.2773) 316\n",
      "tensor(43317.5469) 317\n",
      "tensor(43484.0430) 318\n",
      "tensor(57218.1094) 319\n",
      "tensor(57600.6055) 320\n",
      "tensor(53415.1133) 321\n",
      "tensor(44096.3438) 322\n",
      "tensor(55167.8789) 323\n",
      "tensor(49353.2500) 324\n",
      "tensor(41229.9805) 325\n",
      "tensor(43813.3281) 326\n",
      "tensor(44453.2773) 327\n",
      "tensor(53084.1562) 328\n",
      "tensor(59389.3086) 329\n",
      "tensor(54503.0625) 330\n",
      "tensor(54455.0273) 331\n",
      "tensor(54731.4531) 332\n",
      "tensor(54660.6680) 333\n",
      "tensor(57116.7539) 334\n",
      "tensor(67449.9453) 335\n",
      "tensor(55230.7305) 336\n",
      "tensor(63520.6992) 337\n",
      "tensor(80948.0391) 338\n",
      "tensor(59342.3594) 339\n",
      "tensor(93989.) 340\n",
      "tensor(63306.1445) 341\n",
      "tensor(65799.3516) 342\n",
      "tensor(75909.5078) 343\n",
      "tensor(50722.1250) 344\n",
      "tensor(52490.1445) 345\n",
      "tensor(55442.0117) 346\n",
      "tensor(59571.6133) 347\n",
      "tensor(63815.3281) 348\n",
      "tensor(73100.9453) 349\n"
     ]
    }
   ],
   "source": [
    "batch_size = 1\n",
    "\n",
    "# test_accuracy_history = []\n",
    "# test_loss_history = []\n",
    "\n",
    "# X_test = X_test.to(device)\n",
    "# y_test = y_test.to(device)\n",
    "x = torch.Tensor()\n",
    "y = torch.Tensor()\n",
    "\n",
    "for epoch in range(350):\n",
    "    order = np.random.permutation(len(X_train))\n",
    "\n",
    "    for start_index in range(0, len(X_train), batch_size):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        batch_indexes = order[start_index:start_index+batch_size]\n",
    "\n",
    "\n",
    "        X_batch = X_train[batch_indexes] #.to(device)\n",
    "        y_batch = y_train[batch_indexes] #.to(device)\n",
    "        preds = river_net.forward(X_batch)\n",
    "\n",
    "        # print(\"------------------\")\n",
    "        # print(preds)\n",
    "        # print(y_batch)\n",
    "\n",
    "        loss_value = loss(preds.float(), y_batch.float())\n",
    "        loss_value.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "    test_preds = river_net.forward(X_test)\n",
    "#     test_loss_history.append(loss(test_preds, y_test))\n",
    "    a = []\n",
    "    for i in range(len(y_test)):\n",
    "        a.append((test_preds[i] - y_test[i])**2)\n",
    "\n",
    "    a = torch.Tensor(a)\n",
    "    accuracy = a.float().mean()\n",
    "#     test_accuracy_history.append(accuracy)\n",
    "    print(accuracy, epoch)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1298,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for start_index in range(0, len(X_train), batch_size):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        batch_indexes = order[start_index:start_index+batch_size]\n",
    "\n",
    "\n",
    "        X_batch = X_train[batch_indexes] #.to(device)\n",
    "        y_batch = y_train[batch_indexes] #.to(device)\n",
    "        preds = river_net.forward(X_batch)\n",
    "        x = torch.cat((x, y_batch),dim=0)\n",
    "        y = torch.cat((y, preds),dim=0)\n",
    "k = list([i for i in range(len(y))])\n",
    "plt.plot(numpy.array(k), y.detach().numpy(), 'o', label='Groud truth')\n",
    "plt.plot(numpy.array(k), x.detach().numpy(), 'o', c='r', label='Prediction');\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}